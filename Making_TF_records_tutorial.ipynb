{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c487a7b",
   "metadata": {},
   "source": [
    "## Making TF records from Solar Data Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "#from __future__ import absolute_import, division, print_function\n",
    "#import argparse\n",
    "#import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "#import pdb\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits import getheader\n",
    "import tensorflow as tf\n",
    "from tf_util import example_util\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1429105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the HARPS data that has been shifted and is ready for being added to TF records\n",
    "\n",
    "# set outfile to filename\n",
    "# outfile = 'HARPS2.3.1_ready_for_TF_records.npz'\n",
    "outfile = 'New_HARPS_ready_for_TF_records.npz'\n",
    "# load the file\n",
    "npzfile = np.load(outfile) \n",
    "\n",
    "# List the column names in this file\n",
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc6859-07b4-4a18-9809-f536aaf43729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in npzfile.files:\n",
    "    # Access the array using the key and get its shape\n",
    "#    print(f\"Shape of {key}: {npzfile[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \n",
    "class TfRecordMaker:\n",
    "\n",
    "    def __init__(self, input_path, path, numfits, index=None):\n",
    "        self.input_path = input_path or os.input_path.dirname(os.input_path.realpath(__file__))#or 'shifted_fits_clean73_May26_one_file/'  # or os.path.dirname(os.path.realpath(__file__))\n",
    "        self.path = path or os.path.dirname(os.path.realpath(__file__))\n",
    "        self.numfits = numfits or 0\n",
    "        self.index = index\n",
    "\n",
    "    def make_examples(self):\n",
    "        examples = []\n",
    "        print(self.index)\n",
    "        \n",
    "        index_number = 0\n",
    "        # index = np.arange(0,self.numfits,1)\n",
    "        # np.random.seed(42)\n",
    "        # np.random.shuffle(index)\n",
    "        \n",
    "        \n",
    "        # read in files\n",
    "        npzfile = np.load(outfile) \n",
    "        \n",
    "\n",
    "        for j in self.index:\n",
    "            ex = tf.train.Example()\n",
    "\n",
    "            # Set CCF features.\n",
    "            example_util.set_float_feature(ex, \"OG_CCF\",\n",
    "                                           npzfile['og_ccf_list'][j])\n",
    "            example_util.set_float_feature(ex, \"JUP_CCF\",\n",
    "                                           npzfile['jup_shifted_CCF_data_list'][j])\n",
    "            example_util.set_float_feature(ex, \"ZERO_CCF\",\n",
    "                                           npzfile['zero_shifted_CCF_list'][j])\n",
    "            example_util.set_float_feature(ex, \"CCF\",\n",
    "                                           npzfile['CCF_normalized_list'][j]) \n",
    "            example_util.set_float_feature(ex, \"CCF_residuals\",\n",
    "                                           npzfile['cff_residual_list'][j]) \n",
    "            example_util.set_float_feature(ex, \"Rescaled CCF_residuals\",\n",
    "                                           npzfile['ccf_residual_rescaled'][j]) \n",
    "            example_util.set_float_feature(ex, \"CCF_cutoff\",\n",
    "                                           npzfile['CCF_normalized_list_cutoff'][j]) \n",
    "            example_util.set_float_feature(ex, \"CCF_residuals_cutoff\",\n",
    "                                           npzfile['CCF_residual_list_cutoff'][j]) \n",
    "            example_util.set_float_feature(ex, \"Rescaled CCF_residuals_cutoff\",\n",
    "                                           npzfile['ccf_residual_rescaled_cutoff'][j]) \n",
    "\n",
    "            # prints what iteration we are currently at\n",
    "            index_number = index_number + 1\n",
    "            if index_number % 500 == 0:\n",
    "                print(index_number)\n",
    "\n",
    "            # Set residuals\n",
    "            median_rv = np.median(npzfile['vrad_star'])\n",
    "            # example_util.set_feature(ex, \"activity signal residuals\", act_signal)\n",
    "            example_util.set_feature(ex, \"activity signal\", [(npzfile['vrad_star'][j] - median_rv)])  # in km/s\n",
    "            example_util.set_feature(ex, \"mu_og_fit\", [(npzfile['mu_og_list'][j])])\n",
    "            example_util.set_feature(ex, \"mu_jup_fit\", [(npzfile['mu_jup_list'][j])])\n",
    "            example_util.set_feature(ex, \"mu_zero_fit\", [(npzfile['mu_zero_list'][j])])\n",
    "            example_util.set_feature(ex, \"BJD\", [(npzfile['BJD'][j])])\n",
    "            example_util.set_feature(ex, \"fwhm\", [(npzfile['fwhm'][j])])\n",
    "            example_util.set_feature(ex, \"contrast\", [(npzfile['cont'][j])])\n",
    "            example_util.set_feature(ex, \"bis\", [(npzfile['bis'][j])])\n",
    "\n",
    "            # set the other features in the header\n",
    "            #for k in headr_all[j]:\n",
    "            #    example_util.set_feature(ex, str(k), [headr_all[j][k]])\n",
    "\n",
    "            examples.append(ex)\n",
    "        return examples\n",
    "\n",
    "def tf_writer(input_path, path, numfits, randseed):\n",
    "    num_ccfs = 581 # CHANGE THIS NUMBER TO MATCH OUR DATA SET\n",
    "    full_val_cutoff = int(0.80*num_ccfs) # where 628 is the number of nonzero ccfs\n",
    "    cross_val_cutoff = int(0.08 * num_ccfs)\n",
    "    val_cutoff = int(0.1*num_ccfs)\n",
    "    test_cutoff = int(0.1*num_ccfs)\n",
    "    index = np.arange(0, num_ccfs, 1)\n",
    "    np.random.seed(randseed)\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    reps_bf = []\n",
    "    reps_aft = []\n",
    "    train_indeces = []\n",
    "    intervals = [0.08, 0.16, 0.24, 0.32, 0.40, 0.48, 0.56, 0.64, 0.72, 0.80] # fix this (0.08 each) so it's 0.08*10 = 0.80\n",
    "    for i in range(0, len(intervals)):\n",
    "        if intervals[i] != 0.08:\n",
    "            reps_bf.append(int(intervals[i - 1] * num_ccfs))\n",
    "            reps_aft.append(int(intervals[i] * num_ccfs))\n",
    "            train_indeces.append(index[int(intervals[i - 1] * num_ccfs):int(intervals[i] * num_ccfs)])\n",
    "        else:\n",
    "            print(intervals[i])\n",
    "            reps_bf.append(0)\n",
    "            reps_aft.append(int(intervals[i] * num_ccfs))\n",
    "            train_indeces.append(index[0:int(intervals[i] * num_ccfs)])\n",
    "\n",
    "    subset0 = train_indeces[1:]\n",
    "    subset1 = train_indeces[0:1] + train_indeces[2:]\n",
    "    subset2 = train_indeces[0:2] + train_indeces[3:]\n",
    "    subset3 = train_indeces[0:3] + train_indeces[4:]\n",
    "    subset4 = train_indeces[0:4] + train_indeces[5:]\n",
    "    subset5 = train_indeces[0:5] + train_indeces[6:]\n",
    "    subset6 = train_indeces[0:6] + train_indeces[7:]\n",
    "    subset7 = train_indeces[0:7] + train_indeces[8:]\n",
    "    subset8 = train_indeces[0:8] + train_indeces[9:]\n",
    "    subset9 = train_indeces[0:9]\n",
    "\n",
    "    flattened0 = [val for sublist in subset0 for val in sublist]\n",
    "    flattened1 = [val for sublist in subset1 for val in sublist]\n",
    "    flattened2 = [val for sublist in subset2 for val in sublist]\n",
    "    flattened3 = [val for sublist in subset3 for val in sublist]\n",
    "    flattened4 = [val for sublist in subset4 for val in sublist]\n",
    "    flattened5 = [val for sublist in subset5 for val in sublist]\n",
    "    flattened6 = [val for sublist in subset6 for val in sublist]\n",
    "    flattened7 = [val for sublist in subset7 for val in sublist]\n",
    "    flattened8 = [val for sublist in subset8 for val in sublist]\n",
    "    flattened9 = [val for sublist in subset9 for val in sublist]\n",
    "    indexes_full_val = [val for sublist in train_indeces for val in sublist]\n",
    "\n",
    "    full_train_flats = []\n",
    "    full_train_flats.extend([flattened0, flattened1, flattened2, flattened3, flattened4, flattened5, flattened6, flattened7, flattened8, flattened9])\n",
    "\n",
    "    #train_index = index[0:train_cutoff]\n",
    "    val_index = index[int(0.8 * num_ccfs):int(0.9 * num_ccfs)]\n",
    "    test_index = index[int(0.9 * num_ccfs):]\n",
    "\n",
    "    # # loop through cross_val sets\n",
    "    # for iteration in range(0, len(full_train_flats)):\n",
    "    #     with tf.python_io.TFRecordWriter('Archive_HARPS_N/TF_record_Jul_8/TF_ccf_train'+str(iteration)) as writer:\n",
    "    #         tf_record_maker = TfRecordMaker(path=path, numfits=numfits, index=np.array(full_train_flats[iteration]))\n",
    "    #         number_examples_train = 0\n",
    "    #         examples_tf = tf_record_maker.make_examples()\n",
    "    #         for example in examples_tf[0:train_cutoff]:\n",
    "    #             print(\"train\")\n",
    "    #             number_examples_train = number_examples_train + 1\n",
    "    #             if number_examples_train % 100 == 0:\n",
    "    #                 print(\"iteration for training set: \" + str(number_examples_train))\n",
    "    #             writer.write(example.SerializeToString())\n",
    "    #             # print(ex)\n",
    "\n",
    "    # Make directory if it does not exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    for iteration in range(0, len(train_indeces)):\n",
    "        with tf.io.TFRecordWriter(path+'TF_ccf_cross_val'+str(iteration)) as writer:\n",
    "             tf_record_maker = TfRecordMaker(input_path=input_path, path=path, numfits=numfits, index=train_indeces[iteration])\n",
    "             number_examples_val = 0\n",
    "             eval_counter = 0\n",
    "             #for example in tf_record_maker.make_examples()[train_cutoff:val_cutoff]:\n",
    "             for example in tf_record_maker.make_examples()[0:cross_val_cutoff+1]:\n",
    "                 eval_counter += 1\n",
    "                 print(\"val: \" + str(eval_counter))\n",
    "\n",
    "                 number_examples_val = number_examples_val + 1\n",
    "                 if number_examples_val%100 == 0:\n",
    "                     print(\"iteration for evaluation set: \"+str(number_examples_val))\n",
    "                 writer.write(example.SerializeToString())\n",
    "\n",
    "    with tf.io.TFRecordWriter(path+'TF_ccf_val') as writer:\n",
    "        tf_record_maker = TfRecordMaker(input_path=input_path, path=path, numfits=numfits, index=val_index)\n",
    "        number_examples_test = 0\n",
    "        test_counter = 0\n",
    "        for example in tf_record_maker.make_examples()[0:val_cutoff+1]:\n",
    "        #for example in tf_record_maker.make_examples()[val_cutoff:]:\n",
    "            test_counter += 1\n",
    "            print(\"test: \" + str(test_counter))\n",
    "            number_examples_test = number_examples_test + 1\n",
    "            if number_examples_test % 100 == 0:\n",
    "                print(\"iteration for testing set: \"+str(number_examples_test))\n",
    "            writer.write(example.SerializeToString())\n",
    "            # print(ex)\n",
    "\n",
    "\n",
    "    with tf.io.TFRecordWriter(path+'TF_ccf_test') as writer:\n",
    "        tf_record_maker = TfRecordMaker(input_path=input_path, path=path, numfits=numfits, index=test_index)\n",
    "        number_examples_test = 0\n",
    "        test_counter = 0\n",
    "        for example in tf_record_maker.make_examples()[0:test_cutoff+1]:\n",
    "        #for example in tf_record_maker.make_examples()[val_cutoff:]:\n",
    "            test_counter += 1\n",
    "            print(\"test: \" + str(test_counter))\n",
    "            number_examples_test = number_examples_test + 1\n",
    "            if number_examples_test % 100 == 0:\n",
    "                print(\"iteration for testing set: \"+str(number_examples_test))\n",
    "            writer.write(example.SerializeToString())\n",
    "            # print(ex)\n",
    "\n",
    "    # Optional: also write a file with all the evaluation files in one file\n",
    "    #full_val_cutoff\n",
    "    #indexes_full_val\n",
    "\n",
    "    with tf.io.TFRecordWriter(path+'TF_ccf_full_train') as writer:\n",
    "        tf_record_maker = TfRecordMaker(input_path=input_path, path=path, numfits=numfits, index=indexes_full_val)\n",
    "        number_examples_val = 0\n",
    "        eval_counter = 0\n",
    "        # for example in tf_record_maker.make_examples()[train_cutoff:val_cutoff]:\n",
    "        for example in tf_record_maker.make_examples()[0:full_val_cutoff+1]:\n",
    "            eval_counter += 1\n",
    "            print(\"val: \" + str(eval_counter))\n",
    "            number_examples_val = number_examples_val + 1\n",
    "            if number_examples_val % 100 == 0:\n",
    "                print(\"iteration for evaluation set: \" + str(number_examples_val))\n",
    "            writer.write(example.SerializeToString())\n",
    "            # print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_writer(input_path='/Users/sondo/Astro/rvnet-v2/',\n",
    "          path=\"TF_records_Feb2026/\",\n",
    "          randseed=20,\n",
    "          numfits=len(npzfile['BJD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8cc4a",
   "metadata": {},
   "source": [
    "## Try adding a new feature now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adde7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
